{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc6d3ea-ec73-412c-8fb6-ca7c5a71b8cc",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a9dbf-9c04-4dd7-ab92-e99e2eb4b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image # OpenCV does not support opening GIFs\n",
    "\n",
    "# Get image filenames\n",
    "filenames = [fn for fn in os.listdir(\"images\") if os.path.isfile(f\"images/{fn}\")]\n",
    "\n",
    "# Creates a list of dict in the format of ...\n",
    "# [{'filename': <file name of image>, 'image': <numpy array of pixel values>}, ...]\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    image_path = f\"images/{filename}\"\n",
    "    with Image.open(image_path) as image_pil:\n",
    "        image = np.array(image_pil, dtype=bool)\n",
    "    images.append({'filename': filename, 'image': image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77805b72-3231-4cc5-8f48-d652692f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import image_show\n",
    "imgs = images[340:345]\n",
    "fns = [image['filename'] for image in imgs]\n",
    "imgs = [image['image'] for image in imgs]\n",
    "image_show(imgs, fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d17b4-b360-4016-ae93-d12ee5d8e6f8",
   "metadata": {},
   "source": [
    "# Morphologically open image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b64d9-a6bd-4b76-9804-b22ab02bc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "imgs = [im['image'] for im in images[340:345]]\n",
    "\n",
    "imgs_morph = []\n",
    "for img in imgs:\n",
    "    # Closing and opening\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = img.astype(np.uint8)\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    img = img.astype(bool)\n",
    "    imgs_morph.append(img)\n",
    "\n",
    "image_show(imgs)\n",
    "image_show(imgs_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f42088-fa46-428c-bbcd-5b38731346a6",
   "metadata": {},
   "source": [
    "# Resize and convert RGB for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b136e-787f-48c5-8490-1e0594554820",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [im['image'] for im in images[340:345]]\n",
    "\n",
    "imgs_resized = []\n",
    "for img in imgs:\n",
    "    # Resize to 224 x 224\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((224, 224), resample=Image.Resampling.LANCZOS)\n",
    "    img = img.convert('RGB')\n",
    "    img = np.array(img)\n",
    "    imgs_resized.append(img)\n",
    "\n",
    "image_show(imgs)\n",
    "image_show(imgs_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb628d8-56fd-4d49-b198-f0b2711349f4",
   "metadata": {},
   "source": [
    "# Convert from binary to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0134e-e765-472d-a3d5-f7b8893c1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [im['image'] for im in images[340:345]]\n",
    "\n",
    "imgs_rgb = []\n",
    "for img in imgs:\n",
    "    # Convert to RGB from binary\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('RGB')\n",
    "    img = np.array(img)\n",
    "    imgs_rgb.append(img)\n",
    "\n",
    "image_show(imgs)\n",
    "print(\"Shape of binary image: \", imgs[0].shape)\n",
    "image_show(imgs_rgb)\n",
    "print(\"Shape of converted RGB image: \", imgs_rgb[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38576fa2-838e-4f25-a667-11480aad8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import gaussian_blur\n",
    "\n",
    "imgs_blur = []\n",
    "for img in imgs:\n",
    "    # Convert to RGB from binary\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('RGB')\n",
    "    \n",
    "    # Blur image with kernel size 13 x 13\n",
    "    img = gaussian_blur(img, (13, 13))\n",
    "    \n",
    "    img = np.array(img)\n",
    "    imgs_blur.append(img)\n",
    "    \n",
    "image_show(imgs)\n",
    "image_show(imgs_blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5889f67-3e75-4274-a607-87997a6cf559",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e65a8c-8d22-47d9-8e63-faf270f6f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torchvision.transforms.functional import normalize\n",
    "\n",
    "imgs = [im['image'] for im in images[340:345]]\n",
    "\n",
    "imgs_norm = []\n",
    "for img in imgs:\n",
    "    # Convert to RGB\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert('RGB')\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Convert to tensor and normalize\n",
    "    img = Tensor(img).permute((2, 0, 1))\n",
    "    img = normalize(img, (0.8, 0.9, 0.9), (0.58, 0.5, 0.5))\n",
    "    \n",
    "    imgs_norm.append(img)\n",
    "    \n",
    "image_show(imgs)\n",
    "image_show(imgs_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831872d5-690a-4928-aead-19677487593f",
   "metadata": {},
   "source": [
    "# Mean and std dev for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28398a19-d439-40d2-8fe6-f70c64b089ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimages = 0\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "\n",
    "for img in images:\n",
    "    img = img['image']\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((224, 224), resample=Image.Resampling.LANCZOS)\n",
    "    img = img.convert('RGB')\n",
    "    img = np.array(img)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = img.reshape(*img.shape[:2], -1)\n",
    "    nimages += 1\n",
    "    mean += img.mean(2).sum(0) \n",
    "    var += img.var(2).sum(0)\n",
    "\n",
    "mean /= nimages\n",
    "var /= nimages\n",
    "std = np.sqrt(var)\n",
    "\n",
    "print(mean/255, std/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32536ad-765a-43bb-b1dc-a0626cd959f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmd",
   "language": "python",
   "name": "fmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
